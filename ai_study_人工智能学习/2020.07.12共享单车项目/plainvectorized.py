# -*- coding: utf-8 -*-

# -*- coding: utf-8 -*-
"""
Created on Sun Jun 23 11:04:35 2019

@author: tang

æ•°æ®é›†ä»‹ç» è‡ªè¡Œè½¦å…±äº«ç§Ÿèµè¿‡ç¨‹ä¸ç¯å¢ƒå’Œå­£èŠ‚æ€§ç¯å¢ƒé«˜åº¦ç›¸å…³ã€‚ 
ä¾‹å¦‚ï¼Œå¤©æ°”çŠ¶å†µï¼Œ é™æ°´ï¼Œæ˜ŸæœŸå‡ ï¼Œæ˜¯å¦å·¥ä½œæ—¥æˆ–å‘¨æœ«ï¼Œå­£èŠ‚ï¼Œ
ä¸€å¤©ä¸­çš„å°æ—¶ç­‰éƒ½ä¼šå½±å“å‡ºç§Ÿè¡Œä¸ºã€‚ æ•°æ®é›†æ˜¯ä¸ºæœŸä¸¤å¹´çš„å†å²æ•°æ®ï¼š2011å¹´--2012å¹´
ä¸€ã€æ•°æ®å¯¼å…¥
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
data_path = r'hour.csv'

rides = pd.read_csv(data_path)

#a=pd.DataFrame({'a':[1,2,3],'b':[4,5,6],'c':[7,8,9]})
#rides.head(10)
#rides.shape

#rides.columns
#å¯è§†åŒ–æ–¹æ³•
#rides[:24*10].plot(x='instant', y='cnt')

'''
äºŒã€æ•°æ®é¢„å¤„ç†

1ã€ç¦»æ•£å˜é‡ï¼šç”Ÿæˆå“‘å˜é‡ï¼ˆæˆ–æˆä¸ºone-hotå˜æ¢ï¼‰é‡çº²é—®é¢˜

2ã€å½’ä¸€åŒ–è½¬æ¢ï¼Œæ¶ˆé™¤é‡çº²ã€‚ï¼ˆåˆå§‹å€¼è¾ƒå¤§çš„ï¼Œä¼šä¸¥é‡å½±å“æ¨¡å‹åˆ¤å®šæƒé‡ï¼‰
'''

dummy_fields = ['season', 'weathersit', 'mnth', 'hr', 'weekday']
for each in dummy_fields:
    dummies = pd.get_dummies(rides[each], prefix=each)
    rides = pd.concat([rides, dummies], axis=1)
    print(rides.shape)
    
    
fields_to_drop = ['instant', 'dteday', 'season', 'weathersit', 
                  'weekday', 'atemp', 'mnth', 'workingday', 'hr']
data = rides.drop(fields_to_drop, axis=1)


quant_features = ['casual', 'registered', 'cnt', 'temp', 'hum', 'windspeed']

#ä¿å­˜æ¢ç®—çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ã€‚
#è¿™ä¸ªè¿‡ç¨‹ä¹Ÿè¢«ç§°ä¸ºå½’ä¸€åŒ–ï¼Œè¿™é‡Œå½’ä¸€åŒ–æˆä¸€ä¸ªæ­£å¤ªåˆ†å¸ƒ
scaled_features = {}
for each in quant_features:
    mean, std = data[each].mean(), data[each].std()
    scaled_features[each] = [mean, std]
    data.loc[:, each] = (data[each] - mean)/std



'''
ä¸‰ã€è®­ç»ƒæ•°æ®é›†ï¼ˆ50%-80%ï¼‰ã€éªŒè¯æ•°æ®é›†(è®­ç»ƒä¸­ï¼‰ï¼ˆ20%-5%ï¼‰ã€æµ‹è¯•æ•°æ®é›†ï¼ˆè®­ç»ƒå®Œï¼‰ï¼ˆ20%-10%ï¼‰

éªŒè¯é›†ï¼šéªŒè¯è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æ•ˆæœ,ä»¥ä¾¿å¯¹æ¨¡å‹è¿›è¡Œè°ƒä¼˜ï¼›ï¼ˆå‚ä¸å»ºæ¨¡çš„ï¼‰

æµ‹è¯•é›†ï¼šæœ€ç»ˆè¯„åˆ¤æ¨¡å‹æ•ˆæœã€‚ï¼ˆä¸å‚ä¸å»ºæ¨¡ï¼‰æœ¬é¡¹ç›®ä¸­ï¼šæ‹¿å‡ºäº†æœ€å21å¤©çš„æ•°æ®ä½œä¸ºæµ‹è¯•æ•°æ®é›†ã€‚
'''
test_data = data[-21*24:]


#è®­ç»ƒæ•°æ®é›†ä¸­éœ€è¦ç§»é™¤æ‰ æµ‹è¯•æ•°æ®é›†æ•°æ®
data = data[:-21*24]

#å°†è®­ç»ƒæ•°æ®é›†æ•°æ®æ‹†åˆ†ä¸º ç‰¹å¾å€¼ å’Œç›®æ ‡å€¼
target_fields = ['cnt', 'casual', 'registered']
features, targets = data.drop(target_fields, axis=1), data[target_fields]
test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]
#éªŒè¯è‹±æ–‡ validation
train_features, train_targets = features[:-60*24], targets[:-60*24]
val_features, val_targets = features[-60*24:], targets[-60*24:]

#è¶…å‚æ•°çš„è®¾ç½®
iterations = 6000
learning_rate = 0.5
hidden_nodes = 8
output_nodes = 1
input_nodes = train_features.shape[1]

#åˆå§‹åŒ–æƒé‡
weights_input_to_hidden = np.random.normal(0.0, input_nodes**-0.5, 
               (input_nodes, hidden_nodes))

weights_hidden_to_output = np.random.normal(0.0, hidden_nodes**-0.5, 
               (hidden_nodes, output_nodes))
lr = learning_rate

#è¿™æ˜¯sigmoidçš„æ¿€æ´»å‡½æ•°
activation_function = lambda x : 1/(1+np.exp(-x))  
# Replace 0 with your sigmoid calculation.

### å¦‚æœä½ å¯¹lambdaå‡½æ•°ä¸ç†Ÿæ‚‰ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¦‚ä¸‹æ–¹æ³•ä½œä¸ºæ›¿ä»£
#def sigmoid(x):
#    
#    return 1/(1+np.exp(-x))       # 0 å¤„æ›¿æ¢ä¸ºsigmoid æ¿€æ´»å‡½æ•°
#self.activation_function = sigmoid
'''
è¯¥ç½‘ç»œæœ‰ä¸¤ä¸ªå±‚çº§ï¼Œä¸€ä¸ªéšè—å±‚å’Œä¸€ä¸ªè¾“å‡ºå±‚ã€‚éšè—å±‚çº§å°†ä½¿ç”¨ S å‹å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚
è¾“å‡ºå±‚åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç”¨äºé€’å½’ï¼ŒèŠ‚ç‚¹çš„è¾“å‡ºå’ŒèŠ‚ç‚¹çš„è¾“å…¥ç›¸åŒã€‚å³æ¿€æ´»å‡½æ•°æ˜¯  ğ‘“(ğ‘¥)=ğ‘¥ ã€‚
è¿™ç§å‡½æ•°è·å¾—è¾“å…¥ä¿¡å·ï¼Œå¹¶ç”Ÿæˆè¾“å‡ºä¿¡å·ï¼Œä½†æ˜¯ä¼šè€ƒè™‘é˜ˆå€¼ï¼Œç§°ä¸ºæ¿€æ´»å‡½æ•°ã€‚
æˆ‘ä»¬å®Œæˆç½‘ç»œçš„æ¯ä¸ªå±‚çº§ï¼Œå¹¶è®¡ç®—æ¯ä¸ªç¥ç»å…ƒçš„è¾“å‡ºã€‚ä¸€ä¸ªå±‚çº§çš„æ‰€æœ‰è¾“å‡ºå˜æˆä¸‹ä¸€å±‚çº§ç¥ç»å…ƒçš„è¾“å…¥ã€‚
è¿™ä¸€æµç¨‹å«åšå‰å‘ä¼ æ’­ï¼ˆforward propagationï¼‰ã€‚

æˆ‘ä»¬åœ¨ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨æƒé‡å°†ä¿¡å·ä»è¾“å…¥å±‚ä¼ æ’­åˆ°è¾“å‡ºå±‚ã€‚
æˆ‘ä»¬è¿˜ä½¿ç”¨æƒé‡å°†é”™è¯¯ä»è¾“å‡ºå±‚ä¼ æ’­å›ç½‘ç»œï¼Œä»¥ä¾¿æ›´æ–°æƒé‡ã€‚è¿™å«åšåå‘ä¼ æ’­ï¼ˆbackpropagationï¼‰ã€‚
'''
    
def train(features, targets,weights_input_to_hidden,weights_hidden_to_output):
    ''' Train the network on batch of features and targets. 
    
        Arguments
        ---------
        
        features: 2D array, each row is one data record, each column is a feature
        targets: 1D array of target values
    
    '''
    n_records = features.shape[0]
    delta_weights_i_h = np.zeros(weights_input_to_hidden.shape)
    delta_weights_h_o = np.zeros(weights_hidden_to_output.shape)

    #ä»è¿™é‡Œå¼€å§‹åšå‰å‘è¿ç®—128*56å»çŸ©é˜µä¹˜ä¸€ä¸ª56*8
    hidden_inputs = np.dot(features,weights_input_to_hidden)    # éšè—å±‚è¾“å…¥
    hidden_outputs =activation_function(hidden_inputs)   # éšè—å±‚è¾“å‡º

    #ä»è¿™é‡Œå¼€å§‹æ˜¯éšè—å±‚åˆ°è¾“å‡ºå±‚çš„è¿ç®—
    final_inputs = np.dot(hidden_outputs,weights_hidden_to_output) # æœ€ç»ˆçš„è¾“å‡ºå±‚è¾“å…¥
    final_outputs = final_inputs # æœ€ç»ˆè¾“å‡ºå±‚çš„è¾“å‡º
    
    #### å¼€å§‹éƒ¨ç½²åå‘ä¼ æ’­ ####

    ## éœ€è¦ä½ ç¼–ç¨‹ï¼šè¾“å‡ºå±‚è¯¯å·®
    error = final_outputs-targets[:,None] # è¾“å‡ºå±‚è¯¯å·®=å®é™…å€¼ å‡å» é¢„æµ‹å€¼
    #ç¥ç»ç½‘ç»œé‡Œé¢çš„labelsæ•°æ®ç»“æ„éƒ½æ˜¯[batchsize,num_class]
    #Jå¯¹Zçš„åå¯¼
    delta_output = error
    #ç»è¿‡äº†è¾“å‡ºå±‚æ¿€æ´»å‡½æ•°f'(a)=1

    #è®¡ç®—éšè—å±‚å„è‡ªå¯¹è¯¯å·®çš„è´¡çŒ®
    delta_hidden_outputs = np.dot(delta_output,np.transpose(weights_hidden_to_output))
    
    ##å¯¹error termsè¿›è¡Œåå‘ä¼ æ’­hidden_outputs=f(a)
    delta_hidden_inputs = hidden_outputs*(1-hidden_outputs)*delta_hidden_outputs

    #æƒé‡æ¢¯åº¦æ›´æ–°ï¼ˆè¾“å…¥å±‚ åˆ°  éšè—å±‚ï¼‰
#    delta_weights_i_h=0
#    for feature,delta_hidden_input in zip(features,delta_hidden_inputs):
#        delta_weights_i_h+=np.dot(feature[:,None],delta_hidden_input[None,:])
    #è¿™ä¸€è¡Œä»£ç æ˜¯æœ€éš¾æ‡‚çš„
    
    delta_weights_i_h = np.dot(features.T,delta_hidden_inputs)
    
    # æƒé‡æ¢¯åº¦æ›´æ–°ï¼ˆéšè—å±‚ åˆ° è¾“å‡ºå±‚ï¼‰
    delta_weights_h_o = np.dot(hidden_outputs.T,delta_output)
    
    
    #æ›´æ–°æƒé‡
    weights_hidden_to_output -= lr*delta_weights_h_o/n_records # ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°hidden-to-output weights
    weights_input_to_hidden -= lr*delta_weights_i_h/n_records # ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ›´æ–°input-to-hidden weights
 
def run( features):
    
    
    #### éƒ¨ç½²æ­£å‘ä¼ æ’­ ####
    # éšè—å±‚çš„è¾“å…¥å’Œè¾“å‡º
    hidden_inputs = np.dot(features,weights_input_to_hidden) # éšè—å±‚è¾“å…¥
    hidden_outputs = activation_function(hidden_inputs) # éšè—å±‚è¾“å‡º
    
    # æœ€ç»ˆè¾“å‡ºå±‚çš„è¾“å…¥å’Œè¾“å‡º
    final_inputs =np.dot(hidden_outputs,weights_hidden_to_output)  # æœ€ç»ˆè¾“å‡ºå±‚çš„è¾“å…¥
    final_outputs = final_inputs # æœ€ç»ˆè¾“å‡ºå±‚çš„è¾“å‡º
    
    return final_outputs
    

#è®¡ç®—å‡æ–¹å·®
def MSE(y, Y):
    return np.mean((y-Y)**2)

import sys

### è®¾ç½®è¶…å‚æ•° ###


#N_i = train_features.shape[1]
#network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)
losses = {'train':[], 'validation':[]}
for ii in range(6000):
    
    #æ¯æ¬¡éšæœºä»è®­ç»ƒæ•°æ®é›†ä¸­æŠ½å–128æ¡è®°å½•ä½œä¸ºè®­ç»ƒ
    batch = np.random.choice(train_features.index, size=128)
    X, y = train_features.iloc[batch].values, train_targets.iloc[batch]['cnt'].values
    train(X, y,weights_input_to_hidden,weights_hidden_to_output)
    
    #æ‰“å°å‡ºè®­ç»ƒè¿‡ç¨‹
    train_loss = MSE(run(train_features).T, train_targets['cnt'].values)
    
    val_loss = MSE(run(val_features).T, val_targets['cnt'].values)
    sys.stdout.write("\rProgress: {:2.1f}".format(100 * ii/float(iterations)) \
                     + "% ... Training loss: " + str(train_loss)[:5] \
                     + " ... Validation loss: " + str(val_loss)[:5])
    sys.stdout.flush()
    
    losses['train'].append(train_loss)
    losses['validation'].append(val_loss)# -*- coding: utf-8 -*-

plt.figure()
plt.plot(losses['train'], label='Training loss')
plt.plot(losses['validation'], label='Validation loss')
plt.legend()



_, ax = plt.subplots(figsize=(8,4))
#è¿™é‡Œå¾ˆé‡è¦
mean, std = scaled_features['cnt']
#åŸæ¥å½’ä¸€åŒ–çš„æ—¶å€™æ˜¯å‡å»å‡å€¼å†é™¤ä»¥æ–¹å·®ï¼Œç°åœ¨å°±è¦ä¹˜ä»¥æ–¹å·®å†åŠ ä¸Šå‡å€¼
predictions = run(test_features).T*std + mean

#plt.rcParams['font.sans-serif'] = ['KaiTi'] # æŒ‡å®šé»˜è®¤å­—ä½“
#plt.rcParams['axes.unicode_minus'] = False # è§£å†³ä¿å­˜å›¾åƒæ˜¯è´Ÿå·'-'æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

ax.plot(predictions.T, label='Predict')
ax.plot((test_targets['cnt']*std + mean).values, label='Actual')
ax.legend()

dates = pd.to_datetime(rides.iloc[test_data.index]['dteday'])
dates = dates.apply(lambda d: d.strftime('%b %d'))
ax.set_xticks(np.arange(len(dates))[12::24])
_ = ax.set_xticklabels(dates[12::24], rotation=45)